---
title: "Introduction: fitting a multilevel hidden Markov model"
mainfont: Arial
params:
  answers: true
fontsize: 12pt
urlcolor: blue
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    theme: paper
    pandoc_args: --output=Intro_pract_answers.html
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Install packages, if necessary
if(!requireNamespace("mHMMbayes", quietly = TRUE)) install.packages("mHMMbayes")
if(!requireNamespace("ggmHMM", quietly = TRUE)) devtools::install_github("pepijnvink/ggmHMM") # for visualizations using ggplot2

# Load packages
library(mHMMbayes)
library(ggmHMM)

source('../data/helpers.R')

# Load Data
emotion_data <- readRDS("../data/data_Rowland2020.rds")
emotion_data <- emotion_data[,c('subj_id', 'dayno', 'beep','happy','relaxed','anxious','depressed')]

emotion_data$subj_id2[1] <- 1
for(j in 2:nrow(emotion_data)){
  if(emotion_data$subj_id[j] == emotion_data$subj_id[j-1]){
    emotion_data$subj_id2[j] <- emotion_data$subj_id2[j-1]
  } else {
    emotion_data$subj_id2[j] <- emotion_data$subj_id2[j-1] + 1
  }
}
emotion_data$subj_id <- emotion_data$subj_id2
emotion_data <- subset(emotion_data, select = -c(subj_id2))
```

This is the first practical, where we introduce the dataset and we use it to fit a (2 state) multilevel hidden Markov model. In the more advanced second practical, we will focus on selecting the number of states (which we for now assume to be equal to 2) and perform various forms of model checking.

We have prepared a working directory (the folder called 'Working Directory') for you that contains data and starter R-Markdown files for you to work with. Specifically, it contains:

* The folder "data" which contains an .rds file with the raw data we will be using in this practical.
* "Working Script Practical 1.rmd" and "Working Script Practical 2.rmd", which contains the starter code for these practicals. You can use this to fill in your own answers.
* "helpers.R", which contains some helper functions that we will use to preprocess the data and make plots.
* An R project file. You can open this to start working in the working scripts.

The answers to the practicals are available in the `*_answers.html` files.

In all practicals in this workshop, we make use of the `mHMMbayes` package, version 1.1.0. You can load the package and helper functions using the code below:

```{r, eval=FALSE}
library(mHMMbayes)
source('./helpers.R')
```


## The data

We will use an open access dataset from Rowland and Wenzel (2020), available on OSF [`here`](https://osf.io/jmz2n/). The data consists of one-hundred twenty-five undergraduate students from the University of Mainz in Germany that completed a 40-day ambulatory assessment six times a day, reporting on their affective experiences *happy*, *excited*, *relaxed*, *satisfied*, *angry*, *anxious*, *depressed*, and *sad*. For this exercise we will only use a subset of the variables, namely *happy*, *relaxed*, *anxious*, and *depressed*. These items were scored with a visual analog slider from 0 to 100. Before the collection of the ESM measurements, participants of the study were randomly assigned to a group receiving a weekly mindfulness treatment during the ESM study and a control group. Here we use an already cleaned version of these data from the reproducibility archive of [Haslbeck, Ryan, & Dablander (2023)](https://psyarxiv.com/qudr6), the repository can be found [`here`](https://github.com/jmbh/EmotionTimeSeries), and the specific dataset we will be working with [`here`](https://github.com/jmbh/EmotionTimeSeries/tree/master/DataClean/Rowland2020). However, you do not have to download anything, we provide their cleaned dataset as an `.rds`.

Please use the following code to load the data file:

```{r, eval = FALSE}
emotion_data <- readRDS("./data/data_Rowland2020.rds")
emotion_data <- emotion_data[,c('subj_id', 'dayno', 'beep','happy','relaxed','anxious','depressed')] # only use a subset of variables
```

It is also good practice to reset the subject ID numbers, such that they are consecutive integers starting from 1.:

```{r}
emotion_data$subj_id2[1] <- 1
for(j in 2:nrow(emotion_data)){
  if(emotion_data$subj_id[j] == emotion_data$subj_id[j-1]){
    emotion_data$subj_id2[j] <- emotion_data$subj_id2[j-1]
  } else {
    emotion_data$subj_id2[j] <- emotion_data$subj_id2[j-1] + 1
  }
}
emotion_data$subj_id <- emotion_data$subj_id2
emotion_data <- subset(emotion_data, select = -c(subj_id2))
```

---

**Exercise 1**

**A.** Inspect the first few rows of the emotion data.

```{r, include = params$answers}
# inspect the first few rows
head(emotion_data)
```

**B.** Inspect the data over time using visualization. Most useful is visualizing time sequences for subjects separately, e.g., by using the option `facet_wrap(vars(subj_id))` in ggplot, or density plots.

```{r, warning = FALSE, message = FALSE}
library(ggplot2)

emotion_data$beep2 <- (emotion_data$dayno - 1) * 6 + emotion_data$beep # add a beep number

# Create a long format data frame for ggplot
ggplot_emotion <- rbind(data.frame(ID = emotion_data$subj_id, 
                                 beep2 = emotion_data$beep2, 
                                 outcome = emotion_data$happy,
                                 emotion = "happy"),
                      data.frame(ID = emotion_data$subj_id, 
                                 beep2 = emotion_data$beep2, 
                                 outcome = emotion_data$relaxed,
                                 emotion = "relaxed"),
                      data.frame(ID = emotion_data$subj_id, 
                                 beep2 = emotion_data$beep2, 
                                 outcome = emotion_data$anxious,
                                 emotion = "anxious"),
                      data.frame(ID = emotion_data$subj_id, 
                                 beep2 = emotion_data$beep2, 
                                 outcome = emotion_data$depressed,
                                 emotion = "depressed"))

ggplot_emotion$emotion <- factor(ggplot_emotion$emotion, levels = c("happy", "relaxed", "anxious", "depressed")) # turn the emotion variable into a factor

ggplot(ggplot_emotion[ggplot_emotion$ID %in% c(1:5),]) + # only plot the first 5 subjects
  geom_line(mapping = aes(x = beep2, y = outcome, color = emotion)) + # line plot for time series (different colors for each emotion)
  facet_wrap(vars(ID), ncol = 1) + # plot separate panels for different subjects
  scale_color_manual(values = c("happy" = "darkgreen", "relaxed" = "lightgreen", "anxious" = "darkred", "depressed" = "red")) # color palette

ggplot(ggplot_emotion, aes(x = outcome)) +
  geom_density() +
  facet_wrap(~emotion) # plot separate panels for different emotions
```

---

## Missing data handling and the night gap

Like most EMA studies, the our dataset contains missing measurement points for two reasons: The first are unknown reasons during the day that prevent subjects from responding to the survey. To account for the missingness of measurement points in the multilevel HMM analysis, the missingness must be represented as rows of (missing) NA-values in the data matrix. Otherwise, the package assumes that all measurements are consecutive with an equidistant time between them (six measurements within 10h, so 1h 40 min in our case). The *mHMMbayes* package assumes the data are missing at random. This means that the missingness is equally likely in each of the hidden states.

The second reason for missingness is the fact that subjects do not respond during the night when they are asleep. These missed timepoints are not yet represented in our data. If we left the data as they are, the model would assume that the last measurement in the evening of the day and the first measurement in the morning of the next day are 1 hour and 40 minutes apart, which is clearly incorrect. Instead, we insert a number of NA-values for each night gap for the missed measurements. This assumes that the process during the day continues at night. Since the night gap with no measurements taken was 14h, and the average interval between daytime measurements was 1h 40min, we insert eight missing time steps to represent the night-gap (since the beginning and end of the 14 hours are respectfully the last and first measurement of the day).

**Exercise 2**

Use the `insert_nightgap()` helper function to insert 8 rows of missing values for each subject for each night gap. Call the new dataset `emotion_nightgap`.

```{r}
emotion_nightgap <- insert_nightgap(data = emotion_data, # make sure the first column contains the subject IDs, and the second column contains the day numbers
                                    beeps_per_night = 8, # we want to insert 8 beeps for each night
                                    col_id = 1, # the first column contains the subject IDs
                                    col_day = 2 # the second column contains the day numbers
                                    )
```

## Setting up the multilevel hidden Markov model 

In this section, you will fit a 2-state multilevel hidden Markov model. Note that in an actual analysis we will have to do model selection between models with different number of states. However, here we first get to know the model by assuming that we know the number of states. And will look at model selection in the second practical.

To fit an mHMM with the `mHMMbayes` package, we need a `data.frame` in which only the affective variables we want to use in the model are included, plus the subject ID as the first column.

---

**Exercise 3**
Create a dataset `emotion_mHMM` which has the subject ID variable in the first column, followed by only the affective variables you want to use in the hidden Markov model. 

```{r, include = params$answers}
emotion_mHMM <- emotion_nightgap[,c('subj_id', 'happy', 'relaxed', 'anxious', 'depressed')]
```

---

### Starting Values

Fitting the mlHMM requires setting starting values for all model parameters. Specifically, we need to provide starting values for the group-level means and standard deviations for each variable in each state, as well as for the transition probabilities. The model needs this information to complete the first pass of the iterative estimation algorithm. Sensible initial values help to avoid label switching in the sampling process and are therefore recommended.

We will start with the specification of starting values of the emission distribution (i.e. the state-specific means and standard deviation). If we assume a 2-state model, for the type of variables we model here, it is plausible to assume that we will have a 'positive' state and a 'negative' state. Define the means of the variable and state specific emission distributions to align with this idea. **Do not use equivalent means for one dependent variable over the states!** Sensible would be to base it on the observed data; we can look at the observed range for each variable, and split the data in 2 in the middle of this range, creating 2 subsets. Within each subset, we can then evaluate the median and use these as starting values. This is the approach we will take. Do, however, make sure that the starting values are not too close to the boundary of the observed range, and that the starting values for each state are not too far apart in relation to the standard deviation.

Regarding the standard deviations of the emission distribution, define them such that the emission distribution for state 1 and 2 together cover the entire range of observations (remember, participants could use a slider ranging from 0 to 100) with reasonable support. For example, given our data, it would not make sense to use a standard deviation of 3 (as 95% of the mass of the distribution will only span mean+/- 2 * 3 values out of 100), but a standard deviation of 10 or 15 would make sense.

Also make sure that the combinations of starting values for the different variables are sensible, which is where theory comes in. It will not make sense, for example, to specify the starting values of State 1 such that it has a high mean for both 'happy' and 'depressed'.

---

**Exercise 4**

**A.** Explore the data to determine starting values for the emission distributions.

```{r, eval = params$answers}
# Determine observed range
apply(emotion_mHMM[, 2:5], 2, range, na.rm = TRUE) # observed range is from 0 to 100 for all variables

apply(emotion_mHMM[, 2:5], 2, function(x){
  x_low <- x[x <= 50] # lower range
  x_high <- x[x > 50] # larger range
  c(median(x_low, na.rm = TRUE), median(x_high, na.rm = TRUE))
})

## The lower proposed starting values for anxious and depressed are quite close to the boundary of 0, so we should bring the starting values for state 1 and 2 closer together for these variables.
```

**B** Now, use the obtained values to create input for the model to use as starting values. First, set up the model input arguments: `m` for the number of states the model should infer, `n_dep` for the number of dependent variables used for fitting the model, and then the starting values for the emission distribution, saved in the object `start_emiss`. `start_emiss` should be a list with `n_dep` elements. Each element within the list should be a matrix with 2 columns and `m` rows. The means are contained in the first column of this matrix, and the standard deviations are contained in the second column of the matrix.

```{r, eval = FALSE}
# setting up input parameters
m <- 2
n_dep <- 4

start_emiss <- list(matrix(c(..., ...,                                     # happy
                             ..., ...), byrow = TRUE, ncol = 2, nrow = m),
                    ...,                                     # relaxed,
                    ...,                                     # anxious 
                    ...                                     # depressed)
```

```{r, include = params$answers}
# setting up input parameters
m <- 2
n_dep <- 4

start_emiss <- list(matrix(c(70, 15,                                     # happy
                             30, 15), byrow = TRUE, ncol = 2, nrow = m),
                    matrix(c(70, 15,                                     # relaxed
                             30, 15), byrow = TRUE, ncol = 2, nrow = m),
                    matrix(c(15, 10,                                     # anxious
                             50, 15), byrow = TRUE, ncol = 2, nrow = m), 
                    matrix(c(15, 10,                                     # depressed
                             50, 15), byrow = TRUE, ncol = 2, nrow = m))
```

The next step is to specify starting values for the transition probabilities. `start_gamma` should be a `m` by `m` matrix. The elements on each row should sum to 1.

Make sure that the starting values are sensible. That is, for gamma, usually the elements contained on the diagonal (i.e., the self-transitions) are larger than the off-diagonal values to indicate that from one time point to another, subjects are more likely to remain in the same state than to switch to a new one.

**C.** Set up the starting values for the transition probabilities in the object `start_gamma` using the starter code below.

```{r, eval = FALSE}
start_gamma <- matrix(c(..., ...,
                        ..., ...), byrow = TRUE, ncol = m, nrow = m)
```


```{r, include = params$answers}
start_gamma <- matrix(c(0.7, 0.3, 
                        0.3, 0.7), byrow = TRUE, ncol = m, nrow = m)
```

---

### Specifying Priors

Since the *mHMMbayes* package uses Bayesian estimation, we need to set up priors for the model parameters. Ideally, when available, these reflect the prior knowledge about the parameters The prior for the transition distributions can be set manually using `prior_gamma()`, but we will use the default priors built in the function. For continuous data, the prior for the emission distribution must be set using the `prior_emiss_cont()` function.

**Exercise 5**
Use the `help()` function to inspect the function `prior_emiss_cont()` and its arguments.

```{r, include = params$answers, eval = FALSE}
help(prior_emiss_cont)
```

---

A few considerations should be made when setting up the priors.

* emiss_mu0: the parameters specifying the means for the Normal emission distribution. The means should align with the hypothesized structure of a 'positive emotion' and a 'negative emotion' state. Do not use equivalent means over states within the same dependent variable. It should be a list of *n_dep* matrices (one for each observed variable), each with 1 row and *m* columns (one for each state). The first matrix for example, specifies the prior for the means of 'happy' in state 1 and state 2.
* emiss_K0: the parameters specifying the degrees of freedom for the prior on the means. This can be interpreted as the number of hypothetical observations the prior for the mean (emiss_mu0) is based on. A higher value will make the prior more informative. It should be a list with *n_dep* elements (one for each observed variable), each containing a single value.
* emiss_V: the parameters specifying the hypothesized between-person variance for their means on each state. It should be a list with *n_dep* elements (one for each observed variable), each containing a single value.
* emiss_nu: the parameters specifying the degrees of freedom for the prior on the standard deviations. This can be interpreted as the number of hypothetical observations the prior for the variance (emiss_V) is based on. A higher value will make the prior more informative. It should be a list with *n_dep* elements (one for each observed variable), each containing a single value.
* emiss_a0 and emiss_b0: the parameters specifying respectively the shape and rate of the Inverse Gamma prior on the within-state variances. For an uninformative specification, this is generally set to a low number, such as 0.001 together with the emiss_b0 parameter. More sensible however, is to specify a weakly informative prior, determined by plotting combinations of values for 'emiss_a0' and 'emiss_b0. Both should be a list with *n_dep* elements (one for each observed variable), each containing a single value.

Below, we show an example of such a plot for a weakly informative inverse gamma prior, with a shape of 1.5 and a rate of 20.

```{r, echo = FALSE}
set.seed(42)
a <- 1.5
b <- 20
sample <- 1/rgamma(10000, shape = a, rate = b)
# x11()
ggplot(data.frame(x = sample), aes(x=x)) + geom_density() +
  ggtitle(paste0("Shape ", a, ", rate ", b)) + xlim(c(0, 30)) + xlab("Variance")
```

---

**Exercise 6**
Set up a weakly informative prior for the continuous emission distribution using the function `prior_emiss_cont()` and save the object in `emotion_prior_emiss`. Keep the above considerations in mind. You will only have to fill in the dots below.

```{r, eval = FALSE}
# specifying weakly informative prior for continuous emission distributions

emotion_prior_emiss <- prior_emiss_cont(
  gen = list(m = m, n_dep = n_dep),
  emiss_mu0 = list(...,  # happy
                   ...,  # relaxed
                   ...,  # anxious
                  ...),  # depressed
  emiss_K0 = ...,
  emiss_V = ...,
  emiss_nu = ...,
  emiss_a0 = ...,
  emiss_b0 = ...,
)

```

```{r, include = params$answers}
# specifying weakly informative prior for continuous emission distributions
emotion_prior_emiss <- prior_emiss_cont(
  gen = list(m = m, n_dep = n_dep),
  emiss_mu0 = list(matrix(c(70, 30), nrow = 1),  # happy
                   matrix(c(70, 30), nrow = 1),  # relaxed
                   matrix(c(15, 50), nrow = 1),  # anxious
                   matrix(c(15, 50), nrow = 1)),  # depressed
  emiss_K0 = rep(list(1), n_dep),
  emiss_V = rep(list(rep(5^2, m)), n_dep),
  emiss_nu = rep(list(1), n_dep),
  emiss_a0 = rep(list(rep(1.5, m)), n_dep),
  emiss_b0 = rep(list(rep(20, m)), n_dep),
)
```

---

## Fitting the multilevel hidden Markov model

Now we will use all ingredients to fit a 2 state multilevel hidden Markov model using the function `mHMM()`. For now, set the number of iterations `J` as part of the input parameter `mcmc` to 500, and specify a burn in (`burn_in`) of 200. On a reasonably fast laptop, this should take about 10 minutes. In the meantime, you can have a nice conversation with your neighbor or workshop instructor :) . When fitting a multilevel hidden Markov model for research purposes, we recommend using at least 2.000 iterations, and using traceplots and the Gelman Rubin statistic to ensure convergence with the used number of iterations and the appropriate burn in period. We will discuss convergence in the second practical of this workshop.

---

**Exercise 7**
Fit a 2 state multilevel hidden Markov model using the function `mHMM()`, and save your fitted model in an object named `out_2st_emotion`. See below for the general structure of the `mHMM()` function, you only have to fill in the dots. The provided code assumes continuous observations, no level 2 covariates and only a prior on the Normal emission distribution. 

The function `mHMM()` takes the following arguments that are relevant for now:

* s_data: the dataset to build the model for. The first column should contain the subject IDs, and the subsequent columns should contain the dependent variables.
* data_distr: the distribution of the dependent variables. "continuous" in our case, but also takes "categorical" and "count".
* gen : a list containing the number of states `m` and the number of dependent variables `n_dep`.
* start_val: a list of starting values with `n_dep` + 1 elements. The first element should contain the matrix of starting values for the transition probabilities. Subsequent elements should contain the starting values for the emission distributions for each of the dependent variables. It should not be a nested list (i.e. make sure it does not consist of lists within lists).
* mcmc: a list containing the number of iterations `J` and the burn in period `burn_in`.


```{r, eval = FALSE}
# Run a model without covariate(s) and default priors:
set.seed(...) ## choose a seed for reproducibility
out_2st_emotion <- mHMM(s_data = ...,
                data_distr = "continuous",
                gen = list(m = ..., n_dep = ...),
                start_val = ...,
                mcmc = list(J = 500, burn_in = 200))
```


```{r, eval = FALSE, include = params$answers}
# Run a model without covariate(s) and default priors:
set.seed(42)
out_2st_emotion <- mHMM(s_data = emotion_mHMM,
                        data_distr = "continuous",
                        gen = list(m = m, n_dep = n_dep),
                        start_val = c(list(start_gamma), start_emiss),
                        emiss_hyp_prior = emotion_prior_emiss,
                        mcmc = list(J = 500, burn_in = 200))

```

```{r, include=FALSE}
out_2st_emotion <- readRDS("../data/out_2st_emotion.rds")
```

---

## Inspecting general model output 

**Exercise 8**
Inspect the global output by using the inbuilt `print()` and `summary()` options for a class `mHMM` object created by using the function `mHMM()` within the `mHMMbayes` package. How many subjects were included in the analysis? On average, do students remain within one and the same state for a long time? What mood do each of the states represent?

```{r,  include = params$answers}
# Inspect general model output
out_2st_emotion 

summary(out_2st_emotion)
```

---

To facilitate easy post-processing (e.g., visualizing), the transition probability gamma and emission distribution parameters can be obtained separately and saved within an object using the functions `obtain_gamma()` and `obtain_emiss()`.

---

**Exercise 9**
Save the group level transition probabilities gamma in an object named `gamma_group`, and the group level emission distribution parameters in an object named `emiss_group`, using the functions `obtain_gamma()` and `obtain_emiss()`, respectively. Inspect the objects. 

```{r,  include = params$answers}
# save group level parameters 
gamma_group <- obtain_gamma(out_2st_emotion)
gamma_group

emiss_group <- obtain_emiss(out_2st_emotion) 
emiss_group
```

---

## Visualizing the obtained output  

Especially when you have a large number of states and/or a large number of dependent variables, visualizing the group level parameters can be very helpful. 

In addition to some of the helper functions we provided, there is a package available on GitHub to visualize output created using the `mHMMbayes` package. You can load it as follows:

```{r, eval = FALSE}
devtools::install_github("pepijnvink/ggmHMM") # for visualizations using ggplot2
library(ggmHMM)
```

---

**Exercise 10**
Visualize the group level transition probabilities gamma using a heatmap. You can use the `ggmHMM` function `plot_gamma()`.

```{r, eval = params$answers}
plot_gamma(model = gamma_group) # provide either a model object made with `mHMM()` or a transition matrix obtained with `obtain_gamma()`
```


---

**Exercise 11**
Visualize the group level emission distributions. Various visualizations are possible, for example bar plots depicting the emission distribution means over states and dependent variables (ussing the *ggmHMM* function `plot_emiss()`), or depicting the densities of the normal emission distributions (using the helper function `plot_density()`), combining information on both the mean and standard deviation.

```{r, eval = params$answers}
# Bar chart using the ggmHMM package
plot_emiss(model = out_2st_emotion, subject_effects = FALSE) # bar chart

# density plot using the helper function
plot_dens(model = out_2st_emotion) # density plot
```

---


## Obtaining the most likely sequence of hidden states 

Using the obtained (subject specific) parameter estimates and the complete sequence of observations for each subject, we can infer the most likely sequence of states for each subject. To obtain the probability of each state at each point in time (where the sequence of states with the highest probability forms the sequence of most likely states), we make use of the Viterbi algorithm (Viterbi, 1967). In the package `mHMMbayes`, (an extended version of) the Viterbi algorithm is implemented in the function `vit_mHMM()`. The required input is the object that contains the fitted model generated by the function `mHMM()`, and the data used as input when fitting the multilevel hidden Markov model.

The relevant arguments for the function `vit_mHMM()` are:

* object: the fitted model object created by the function `mHMM()`
* s_data: the dataset used to build the model

---

**Exercise 12**
Using the function `vit_mHMM()`, the object `out_2st_emotion` containing our fitted multilevel HMM model, and the data `emotion_mHMM`, obtain the most likely hidden state sequence. Save the state sequences in the object `emotion_states_2st`, and inspect the object.

```{r,  include = params$answers}
emotion_states_2st <- vit_mHMM(out_2st_emotion, emotion_mHMM)
head(emotion_states_2st)
table(emotion_states_2st$subj, emotion_states_2st$state)
```

---

To inspect the obtained most likely state sequences, plotting them is most useful. State sequences can be plotted per subject, or alternatively, together with the observed data. The *ggmHMM* package contains a function `plot_viterbi()`, which can be used to plot a barcode plot of the most likely state sequences over time. It takes the following arguments:

* states: the state sequences obtained using the function `vit_mHMM()`, or an object created using `mHMM()`.
* s_data: a dataframe used to build the model. Not necessary when `states` is an object created using `vit_mHMM()`.
* subject: an integer or vector specifying the subjects to plot.

---

**Exercise 13**
Use the *ggmHMM* function `plot_viterbi()` to plot the inferred state sequence over a time for a selection of the subjects within the data.

```{r,  include = params$answers}
plot_viterbi(states = emotion_states_2st, subject = 1:10)
```

---


## Conclusion 

In this first practical, we have loaded and inspected our data, fitted a simple 2 state multilevel hidden Markov model, investigated and visualized our group level parameters, and obtained (and visualized) the most likely sequence of hidden states. In the next practical, we well focus on the model selection problem (how many states should we use), obtaining and interpreting subject specific parameters, and model checking (inspecting convergence and using posterior predictive checks and pseudoresiduals to assure a good match between the model and the observed data). If you finished early with this part, feel free to already start on the second part (or take a slightly longer break).

---

## References
- Aarts, E., & Haslbeck, J. M. B. (2025, April 3). Modelling Psychological Time Series with Multilevel Hidden Markov Models: A Numerical Evaluation and Tutorial. PsyArXiv Doi: 10.31234/osf.io/y2u5s_v2.
- Haslbeck, J., Ryan, O., & Dablander, F. (2023). Multimodality and skewness in emotion time series. Emotion, 23(8), 2117–2141. DOI: 10.1037/emo0001218.
- Rowland, Z. & Wenzel, M. (2020). Mindfulness and affect-network density: Does mindfulness facilitate disengagement from affective experiences in daily life?. Mindfulness, 11(5), 1253-1266. DOI: 10.1007/s12671-020-01335-4
- Viterbi, A. (1967). “Error bounds for convolutional codes and an asymptotically optimum decoding algorithm.” IEEE transactions on Information Theory, 13(2), 260–269.
